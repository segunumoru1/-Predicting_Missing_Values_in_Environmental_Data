{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/segunumoru1/-Predicting_Missing_Values_in_Environmental_Data/blob/master/Final_working_stage_II_Project_Test_(Used_to_extract_info_from_PDF)_LangChainWithFiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-OwI3GsMUw1"
      },
      "source": [
        "# **Background**\n",
        "The field of Generative AI Assistants for Government forms has been a subject of growing interest and scholarly investigation in recent years. As a need to address the challenge of assisting individuals, particularly those with disabilities such as the deaf, the blind, etc., in completing government forms like the Adult Disability Payment Form. Understanding the various perspectives and developments within this domain has become increasingly crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09eru8eENGiy"
      },
      "source": [
        "## Problem Statetment\n",
        "Develop an AI Assistant Chatbot in filling Government Disability Forms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JLiJgSUOP3s",
        "outputId": "49f0811a-0b07-45a4-99b9-9682db0da41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Collecting langchain==0.1.0\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.0)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain==0.1.0)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.0)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain==0.1.0)\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0) (3.7.1)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain==0.1.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0) (1.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.0 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.21.3 mypy-extensions-1.0.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.37.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.37.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.37.0 watchdog-4.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.1\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.2 pypdfium2-4.30.0\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting PyMuPDFb==1.24.9 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.9 PyMuPDFb-1.24.9\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (23.2)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-docx, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-docx-1.1.2 python-pptx-0.6.23\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,653 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123589 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=b69812f625d867a87125ea44491a6c35f92111ca56f0413cd194a7172088f79b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt, pytesseract\n",
            "Successfully installed docx2txt-0.8 pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "# pip install all the necessary dependencies\n",
        "!pip install python-dotenv\n",
        "!pip install requests\n",
        "!pip install langchain==0.1.0\n",
        "!pip install streamlit\n",
        "!pip install openai\n",
        "!pip install pdfplumber\n",
        "!pip install PyMuPDF  # PyMuPDF\n",
        "!pip install pyngrok\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "!pip install faiss-cpu\n",
        "!pip install python-docx python-pptx\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract pillow docx2txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyzRcTmxQkc8"
      },
      "source": [
        "### **Core Libraries**\n",
        "\n",
        "*openai:* The official OpenAI Python library, used to interact with OpenAI's models like GPT-3.5 and GPT-4 for text generation, translation, question answering, and more.\n",
        "\n",
        "*requests:* A popular library for making HTTP requests to web services and APIs, allowing you to fetch data from the internet.\n",
        "\n",
        "*os:* Python's built-in library for interacting with the operating system, providing functionalities like file system navigation and environment variable management.\n",
        "\n",
        "*datetime:* Python's built-in library for handling dates and times, useful for scheduling tasks, logging events, and working with time-sensitive data.\n",
        "\n",
        "*pdfplumber*: This is a Python library for extracting text and other information from PDF files.\n",
        "\n",
        "*PyMuPDF (fitz)*: This is a Python binding for the MuPDF library, which is used for working with PDF and other document formats.\n",
        "\n",
        "*pyngrok*: This is a Python library that allows you to expose a local web server to the internet using the ngrok service.\n",
        "\n",
        "*tiktoken*: This is a Python library for fast encoding and decoding of text using the Byte Pair Encoding (BPE) algorithm.\n",
        "\n",
        "*faiss-gpu and faiss-cpu*: These are Python libraries for efficient similarity search and clustering of dense vectors, with GPU and CPU support respectively.\n",
        "\n",
        "*python-docx and python-pptx*: These are Python libraries for creating and manipulating Microsoft Word (DOCX) and PowerPoint (PPTX) documents.\n",
        "\n",
        "*tesseract-ocr*: This is an open-source Optical Character Recognition (OCR) engine that can be used to extract text from images.\n",
        "\n",
        "*pytesseract*: This is a Python wrapper for Google's Tesseract-OCR Engine, which allows you to use Tesseract-OCR from within your Python code.\n",
        "\n",
        "*pillow*: This is a Python Imaging Library (PIL) that provides image processing capabilities.\n",
        "\n",
        "*docx2txt*: This is a Python library that can extract text from Microsoft Word (DOCX) documents.\n",
        "\n",
        "**LangChain**\n",
        "\n",
        "*langchain.chat_models.ChatOpenAI*: Provides a wrapper for interacting with OpenAI's chat models in a more structured way, facilitating the creation of conversational agents.\n",
        "\n",
        "*langchain.chains.LLMChain:* A core component of LangChain that allows you to chain together language models and other components to create more complex workflows.\n",
        "\n",
        "*langchain.memory.ConversationBufferWindowMemory*: A type of memory that stores a history of the conversation, allowing the language model to maintain context and provide more relevant responses.\n",
        "\n",
        "*langchain.prompts.PromptTemplate:* A tool for creating and managing prompts for language models, making it easier to structure and customize your interactions with the model.\n",
        "Other\n",
        "\n",
        "*streamlit:* A framework for building interactive web applications for data science and machine learning, allowing you to easily create user interfaces for your models and data.\n",
        "\n",
        "*python-dotenv:* A library for loading environment variables from a .env file, helping you manage sensitive information like API keys securely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8hUip_ptkjjC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xa0AXPphkmEo"
      },
      "outputs": [],
      "source": [
        "# Get the API key from the environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NbWVVohZnHM",
        "outputId": "4f6fa89e-1ed7-44fd-f29b-063dcc0e7ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-G_dqnivRSmI"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "import fitz  # PyMuPDF\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "import datetime\n",
        "import warnings\n",
        "import tiktoken\n",
        "import faiss\n",
        "import fitz  # PyMuPDF\n",
        "from docx import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    StringPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    BaseChatPromptTemplate\n",
        ")\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import fitz  # PyMuPDF\n",
        "from docx import Document\n",
        "import docx2txt\n",
        "import io\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do9-jgzwgk8y"
      },
      "source": [
        "This is the LangChain Bot version with document access for Context Augmentation.\n",
        "It includes:\n",
        "*   dialogue memory\n",
        "*   dialogue logging on file\n",
        "*   document access in the Prompt\n",
        "\n",
        "CAUTION: large pdf documents tend to slow down the ChatBot and cost more tokens. A reasonable size is up to 5 pages.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-Ifnq96rPI-E",
        "outputId": "1ff28abf-0b48-4c37-e9c2-f59d01be8cb5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98f03450-d4b2-4470-aafd-ca5beb55ed8c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-98f03450-d4b2-4470-aafd-ca5beb55ed8c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Referrral Form 03.pdf to Referrral Form 03.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W6Ch4_ZbpxH"
      },
      "source": [
        "1. from google.colab import files: This line imports the files module from the google.colab library. This module provides functions for interacting with the Colab file system, including uploading and downloading files.\n",
        "\n",
        "2. uploaded = files.upload(): This line calls the upload() function from the files module. When executed, it displays a button in the Colab notebook that allows the user to select files from their local machine to upload. The uploaded files are stored in the Colab environment and a dictionary is returned, where keys are the file names and values are the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGj7JuI3uh-R"
      },
      "outputs": [],
      "source": [
        "# PDF Extraction Class objects and method for processing and vector embeddings\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def __init__(self):\n",
        "        self.text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        self.vectorstore = None\n",
        "\n",
        "    def process_pdf(self, pdf_path):\n",
        "        doc = fitz.open(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "\n",
        "            # Extract images\n",
        "            images = page.get_images(full=True)\n",
        "            for img_index, img in enumerate(images):\n",
        "                xref = img[0]\n",
        "                base_image = doc.extract_image(xref)\n",
        "                image_bytes = base_image[\"image\"]\n",
        "\n",
        "                # Use PIL to open the image\n",
        "                image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "                # Perform OCR on the image\n",
        "                image_text = pytesseract.image_to_string(image)\n",
        "                text += f\"\\nImage {img_index + 1} text:\\n{image_text}\\n\"\n",
        "\n",
        "        return text\n",
        "\n",
        "    def process_docx(self, docx_path):\n",
        "        # Extract text\n",
        "        text = docx2txt.process(docx_path)\n",
        "\n",
        "        # Extract images\n",
        "        temp_dir = \"temp_images\"\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        docx2txt.process(docx_path, temp_dir)\n",
        "\n",
        "        # Perform OCR on extracted images\n",
        "        for img_file in os.listdir(temp_dir):\n",
        "            if img_file.endswith(('png', 'jpg', 'jpeg', 'tiff')):\n",
        "                img_path = os.path.join(temp_dir, img_file)\n",
        "                image_text = self.extract_text_from_image(img_path)\n",
        "                text += f\"\\nImage {img_file} text:\\n{image_text}\\n\"\n",
        "                os.remove(img_path)  # Clean up the temporary image file\n",
        "\n",
        "        os.rmdir(temp_dir)  # Remove the temporary directory\n",
        "        return text\n",
        "\n",
        "    def extract_text_from_image(self, image_path):\n",
        "        image = Image.open(image_path)\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return text\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        _, file_extension = os.path.splitext(file_path)\n",
        "        if file_extension.lower() == '.pdf':\n",
        "            return self.process_pdf(file_path)\n",
        "        elif file_extension.lower() in ['.docx', '.doc']:\n",
        "            return self.process_docx(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    def add_document(self, file_path):\n",
        "        text = self.process_file(file_path)\n",
        "        texts = self.text_splitter.split_text(text)\n",
        "\n",
        "        if self.vectorstore is None:\n",
        "            self.vectorstore = FAISS.from_texts(texts, self.embeddings)\n",
        "        else:\n",
        "            self.vectorstore.add_texts(texts)\n",
        "\n",
        "    def search(self, query, k=3):\n",
        "        if self.vectorstore is None:\n",
        "            return []\n",
        "        return self.vectorstore.similarity_search(query, k=k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDsdwH5ewjlk",
        "outputId": "cf286cfd-199d-494d-b56b-7dcd28075eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Image 1 text:\\n  \\n  \\n\\n  \\n\\nPERSONAL DETAILS (cont.)\\n\\nLiving Arrangements:\\n\\n \\n         \\n     \\n   \\n \\n    \\n      \\n  \\n   \\n\\nCarer role in household Living with parents/guardian\\n\\nCaring for Children Living with partner\\nLiving alone Living with other relatives/friends\\n\\nLiving in homeless unit Looked after at home\\n\\na. o-oo @\\n\\nLiving in residential/secure accommodation Other (please specify)\\n\\nae: ee oe\\n\\nLiving in supported accommodation\\n\\n \\n   \\n\\nLiving with foster CTO => «= (titi eine ae eta MD ain seas naan Nes kd Aen wem nena seevencnsecensonane ness\\n\\nGP Telephone No:\\nActual Name of Practice: CHI Number\\n\\nDoes the person have any medical/mental health conditions? O YES 0 NO\\nPlease give details :\\n\\n  \\n\\n|\\nxy\\n\\n  \\n\\n  \\n\\nIs the person taking any form of medication? O YES LINO\\n\\nIf so please indicate what type:\\n\\nREFERRAL DETAILS\\nReferrer: Relationship to service user:\\nAddress:\\n\\nPostcode:\\n\\nIs the person aware of the service and in agreement to the Referral? OF YES 0 NO'), Document(page_content='Image 1 text:\\nREFERRAL DETAILS (cont.)\\n\\n   \\n   \\n\\nFamily Issues Physical Health/IIIness | Trauma\\n\\nInterpersonal/ Pregnancy | Work/Academic/Training\\n\\nRelationship difficulties ;\\nPsychosis | Other (please state)\\n\\nLiving/Welfare/Housing ibicnt ieee\\n\\nLoneliness\\nSelf-Harm\\n\\nPersonality/Challenging\\n\\nBahiaviacr Suicidal Ideation/Behaviour\\n\\nRISK ASSESSMENT, SAFEGUARDING OR PROTECTION ISSUES\\n\\nDo you know of any areas of risk/concern that RAMH should be aware of Cl YES “NS\\n\\nPlease provide details, including guidance on what action, e.g. FIRST Crisis should take, if they are\\nunable to make initial contact with the service user, is there anyone you would like us to contact?:\\n\\n   \\n\\n  \\n  \\n\\n  \\n  \\n\\nSIAR nsession ed vats Date RETSIED? sais. ccccstanccha communal\\n\\n_oee eer ——— — eee\\n\\nAppolrtrnent Dates sisiciccsiscsccscccesscissecscessosecsoccnsecssconsees\\n\\nPI POUTEIOINE THRE jitesseiccccccincicimnninnsancaalaneaic'), Document(page_content='O Mixed Background Ey), Geer ERM Groep Be WB rcs canst) ersdsvenceoreressneesrendiovemnomenenmmnseneiennase\\n\\nIs it ok to contact the person by phone/letter/email at home/work/mobile?\\n\\nHome: YES NO Work: YES NO Leave amessage: YES NO\\nMobile: YES NO Letter to Home: YES NO Ok to identify service: YES NO\\nEmail: YES NO Consent SMS: IYES_ NO GDPR Confidentiality: YES NO\\n\\nOther Supports OO YES O NO\\n\\nTel:\\n\\nContact:')]\n"
          ]
        }
      ],
      "source": [
        "# Usage example:\n",
        "processor = DocumentProcessor()\n",
        "processor.add_document('/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 01.pdf')\n",
        "processor.add_document('/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 02.pdf')\n",
        "processor.add_document('/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 03.pdf')\n",
        "results = processor.search(\"personal details\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8X5LBhHYJwQ"
      },
      "outputs": [],
      "source": [
        "# Disability Form Assistant class\n",
        "\n",
        "class DisabilityFormAssistant:\n",
        "    def __init__(self, pdf_paths, model=\"gpt-4o\", temperature=0.7):\n",
        "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        openai.api_key = self.api_key\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.llm = self._setup_llm()\n",
        "        self.document_processor = DocumentProcessor()\n",
        "        self.memory = ConversationBufferWindowMemory(memory_key=\"history\", input_key=\"human_input\")\n",
        "        self.chat_chain = self._setup_chat_chain()\n",
        "\n",
        "        for pdf_path in pdf_paths:\n",
        "            self.add_document(pdf_path)\n",
        "\n",
        "    def _setup_llm(self):\n",
        "        return ChatOpenAI(model=self.model, temperature=self.temperature)\n",
        "\n",
        "    def _setup_chat_chain(self):\n",
        "        template = \"\"\"\n",
        "        Act as if you are a professional assistant specialized in helping people with disabilities fill out official documentation.\\\n",
        "        Never ever mention that you are an AI or a language model.\\\n",
        "        You provide step-by-step guidance to fill out forms accurately.\\\n",
        "        You can answer questions about the entire process.\\\n",
        "\n",
        "        Take all procedure from the website https://www.mygov.scot/adult-disability-payment\\\n",
        "        Break down complex instructions into simple, manageable steps.\\\n",
        "\n",
        "        In your answer, write each sentence in one line to aid reading.\\\n",
        "        Include specific references to sections and pages of the documents when applicable.\\\n",
        "\n",
        "        If you cannot find the answer in the material, then state that the answer is not in the document.\\\n",
        "\n",
        "        This is your prompt.\n",
        "\n",
        "        Context from the document:\n",
        "        {context}\n",
        "\n",
        "        {history}\n",
        "        Human: {human_input}\n",
        "        Assistant:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(input_variables=[\"context\", \"history\", \"human_input\"], template=template)\n",
        "        return LLMChain(llm=self.llm, prompt=prompt, memory=self.memory)\n",
        "\n",
        "    def add_document(self, file_path):\n",
        "        self.document_processor.add_document(file_path)\n",
        "\n",
        "    def get_response(self, query):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Retrieve relevant context from the vectorstore\n",
        "        docs = self.document_processor.search(query, k=3)\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs]) if docs else \"\"\n",
        "\n",
        "        # Generate response using the chat chain\n",
        "        response = self.chat_chain.predict(human_input=query, context=context)\n",
        "\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        return response, response_time\n",
        "\n",
        "    def get_user_rating(self):\n",
        "        while True:\n",
        "            try:\n",
        "                rating = int(input(\"Please rate your experience (1-5): \"))\n",
        "                if 1 <= rating <= 5:\n",
        "                    return rating\n",
        "                else:\n",
        "                    print(\"Please enter a number between 1 and 5.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def save_dialogue(self, dialogue):\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
        "        filename = f\"Dialogue_{timestamp}.txt\"\n",
        "        with open(filename, \"w\") as file:\n",
        "            file.write(dialogue)\n",
        "        print(f\"Dialogue saved to {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2NilO_cTUnUz",
        "outputId": "6f20cfce-ea98-4d12-9e93-56624a912a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! I'm here to assist you with the Adult Disability Payment form.\n",
            "Type 'exit' to end the conversation.\n",
            "You can also type 'add document' to add a new document to the knowledge base.\n",
            "User > Hello.  can you help me with filling my form?\n",
            "Assistant: Of course, I'd be happy to help you fill out your form. Let's begin by going through each section step-by-step. Please have your form in front of you, and let's start with the \"Personal Details\" section.\n",
            "\n",
            "### Personal Details\n",
            "1. **Living Arrangements:**\n",
            "   - Select the option that best describes your current living situation. Options include:\n",
            "     - Living with parents/guardian\n",
            "     - Living with partner\n",
            "     - Living alone\n",
            "     - Living with other relatives/friends\n",
            "     - Living in a homeless unit\n",
            "     - Looked after at home\n",
            "     - Living in residential/secure accommodation\n",
            "     - Living in supported accommodation\n",
            "     - Living with foster care\n",
            "     - Other (please specify)\n",
            "   \n",
            "2. **GP Telephone No:**\n",
            "   - Enter the telephone number of your General Practitioner (GP).\n",
            "   \n",
            "3. **Actual Name of Practice:**\n",
            "   - Enter the name of the medical practice you attend.\n",
            "   \n",
            "4. **CHI Number:**\n",
            "   - Enter your Community Health Index (CHI) number, if known.\n",
            "\n",
            "5. **Medical/Mental Health Conditions:**\n",
            "   - Indicate if you have any medical or mental health conditions by selecting \"Yes\" or \"No.\"\n",
            "   - If \"Yes,\" please provide details of your conditions.\n",
            "\n",
            "6. **Medication:**\n",
            "   - Indicate if you are taking any form of medication by selecting \"Yes\" or \"No.\"\n",
            "   - If \"Yes,\" please specify the type of medication.\n",
            "\n",
            "### Referral Details\n",
            "1. **Referrer:**\n",
            "   - Enter the name of the person making the referral.\n",
            "   \n",
            "2. **Relationship to Service User:**\n",
            "   - Specify the relationship of the referrer to you (e.g., self, family member, healthcare professional).\n",
            "\n",
            "3. **Address and Postcode:**\n",
            "   - Enter the referrer's address and postcode.\n",
            "\n",
            "4. **Awareness and Agreement:**\n",
            "   - Indicate if you are aware of the service and agree to the referral by selecting \"Yes\" or \"No.\"\n",
            "\n",
            "### Service Requirements\n",
            "1. **Service Selection:**\n",
            "   - If you know the service you require, tick the appropriate box. Options include:\n",
            "     - East Renfrewshire: Community Services, Housing Support, Community Link, Information, Counselling, Youth Counselling, Employability, Restore\n",
            "     - Renfrewshire: Community Services, Information, Employability, FIRST, Housing Support, Restore\n",
            "     - North Ayrshire: Recovery College\n",
            "\n",
            "### Contact Details\n",
            "1. **Address:**\n",
            "   - Enter your address.\n",
            "\n",
            "2. **Telephone Numbers:**\n",
            "   - Enter your home, work, and mobile telephone numbers.\n",
            "\n",
            "3. **Ethnicity:**\n",
            "   - Select your ethnicity from the options provided:\n",
            "     - Asian or Asian British\n",
            "     - Black or Black British\n",
            "     - White or White British\n",
            "     - Mixed Background\n",
            "     - Other\n",
            "\n",
            "4. **Contact Preferences:**\n",
            "   - Indicate if it is OK to contact you by phone, letter, email at home or work, and if messages can be left. Options include:\n",
            "     - Home: Yes/No\n",
            "     - Work: Yes/No\n",
            "     - Leave a message: Yes/No\n",
            "     - Mobile: Yes/No\n",
            "     - Letter to Home: Yes/No\n",
            "     - OK to identify service: Yes/No\n",
            "     - Email: Yes/No\n",
            "     - Consent SMS: Yes/No\n",
            "     - GDPR Confidentiality: Yes/No\n",
            "\n",
            "### Other Supports\n",
            "1. **Other Supports:**\n",
            "   - Indicate if you have any other supports by selecting \"Yes\" or \"No.\"\n",
            "   - If \"Yes,\" provide details including the type of support, telephone number, and contact person.\n",
            "\n",
            "Please let me know if you need further assistance with any specific section or if you have any questions about the process.\n",
            "Response time: 14.01 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-bff55f67a64c>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-bff55f67a64c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User > \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdialogue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"User: {user_input}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    pdf_paths = [\"/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 01.pdf\",\n",
        "                 \"/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 02.pdf\",\n",
        "                 \"/content/drive/MyDrive/Datasets/PDFs_DB/Referrral Form 03.pdf\"]  # Add your PDF paths here\n",
        "    assistant = DisabilityFormAssistant(pdf_paths)\n",
        "    dialogue = \"\"\n",
        "\n",
        "    print(\"Welcome! I'm here to assist you with the Adult Disability Payment form.\")\n",
        "    print(\"Type 'exit' to end the conversation.\")\n",
        "    print(\"You can also type 'add document' to add a new document to the knowledge base.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"User > \")\n",
        "        dialogue += f\"User: {user_input}\\n\"\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        elif user_input.lower() == 'add document':\n",
        "            file_path = input(\"Enter the path to the document: \")\n",
        "            assistant.add_document(file_path)\n",
        "            print(\"Document added successfully!\")\n",
        "            dialogue += f\"Document added: {file_path}\\n\"\n",
        "            continue\n",
        "\n",
        "        response, response_time = assistant.get_response(user_input)\n",
        "        print(f\"Assistant: {response}\")\n",
        "        print(f\"Response time: {response_time:.2f} seconds\")\n",
        "\n",
        "        dialogue += f\"Assistant: {response}\\n\"\n",
        "        dialogue += f\"Response time: {response_time:.2f} seconds\\n\\n\"\n",
        "\n",
        "    rating = assistant.get_user_rating()\n",
        "    dialogue += f\"User rating: {rating}/5\\n\"\n",
        "\n",
        "    assistant.save_dialogue(dialogue)\n",
        "    print(f\"Thank you for your rating: {rating}/5\")\n",
        "    print(\"Thank you for using the Disability Form Assistant. Goodbye!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzgZPOF-mZMq"
      },
      "source": [
        "# Break down:\n",
        "1. I have added the necessary libraries for PDF processing and vector storage.\n",
        "\n",
        "2. The process_pdf function extracts text from the PDF, splits it into chunks, and creates a vector store for efficient searching.\n",
        "\n",
        "3. The DisabilityFormAssistant class now takes a pdf_path parameter and uses the processed PDF as the primary source of information.\n",
        "\n",
        "4. The get_response method now retrieves relevant context from the vector store before generating a response.\n",
        "The prompt template has been updated to include the context from the PDF."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}